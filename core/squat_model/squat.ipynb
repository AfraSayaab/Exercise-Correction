{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing helpers\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Make some detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_frame(frame, percent=50):\n",
    "    '''\n",
    "    Rescale a frame to a certain percentage compare to its original frame\n",
    "    '''\n",
    "    width = int(frame.shape[1] * percent/ 100)\n",
    "    height = int(frame.shape[0] * percent/ 100)\n",
    "    dim = (width, height)\n",
    "    return cv2.resize(frame, dim, interpolation =cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"../data/squat_right_4.mp4\")\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, image = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Recolor image from BGR to RGB for mediapipe\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Recolor image from BGR to RGB for mediapipe\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Draw landmarks and connections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS, mp_drawing.DrawingSpec(color=(244, 117, 66), thickness=2, circle_radius=4), mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "        cv2.imshow(\"CV2\", image)\n",
    "\n",
    "        cv2.imshow(\"Media Pipe feed\", image)\n",
    "        \n",
    "        # Press Q to close cv2 window\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # (Optional)Fix bugs cannot close windows in MacOS (https://stackoverflow.com/questions/6116564/destroywindow-does-not-close-window-on-mac-using-python-and-opencv)\n",
    "    for i in range (1, 5):\n",
    "        cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Save video from CV2 to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional, use it to save live video from webcam\n",
    "cap = cv2.VideoCapture(0) # Capture video from camera\n",
    "\n",
    "# Get the width and height of frame\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5)\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Be sure to use the lower case\n",
    "out = cv2.VideoWriter('../data/webcam.mp4', fourcc, 20.0, (width, height))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        frame = cv2.flip(frame,0)\n",
    "\n",
    "        # write the flipped frame\n",
    "        out.write(frame)\n",
    "\n",
    "        cv2.imshow('frame', frame)\n",
    "\n",
    "    # Press Q to close cv2 window\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# (Optional)Fix bugs cannot close windows in MacOS (https://stackoverflow.com/questions/6116564/destroywindow-does-not-close-window-on-mac-using-python-and-opencv)\n",
    "for i in range (1, 5):\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Capture landmarks and Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Data Frame\n",
    "\n",
    "The data frame will be saved in a .csv file.\n",
    "\n",
    "A data frame will contains a \"Label\" columns which represent the label of a data point\n",
    "There are another 9 x 4 columns represent 9 features of a human pose that are important for a squat.\n",
    "\n",
    "In that each landmark's info will be flatten\n",
    "\n",
    "According to the [Mediapipe documentation](https://google.github.io/mediapipe/solutions/pose#python-solution-api),\n",
    "Each landmark consists of the following:\n",
    "- x and y: Landmark coordinates normalized to [0.0, 1.0] by the image width and height respectively.\n",
    "- z: Represents the landmark depth with the depth at the midpoint of hips being the origin, and the smaller the value the closer the landmark is to the camera. The magnitude of z uses roughly the same scale as x.\n",
    "- visibility: A value in [0.0, 1.0] indicating the likelihood of the landmark being visible (present and not occluded) in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine important landmarks for squat\n",
    "\n",
    "IMPORTANT_LMS = [\n",
    "    \"NOSE\",\n",
    "    \"LEFT_SHOULDER\",\n",
    "    \"RIGHT_SHOULDER\",\n",
    "    \"LEFT_HIP\",\n",
    "    \"RIGHT_HIP\",\n",
    "    \"LEFT_KNEE\",\n",
    "    \"RIGHT_KNEE\",\n",
    "    \"LEFT_ANKLE\",\n",
    "    \"RIGHT_ANKLE\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all columns of the data frame\n",
    "\n",
    "landmarks = [\"label\"] # Label column\n",
    "\n",
    "for lm in IMPORTANT_LMS:\n",
    "    landmarks += [f\"{lm.lower()}_x\", f\"{lm.lower()}_y\", f\"{lm.lower()}_z\", f\"{lm.lower()}_v\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nose_x',\n",
       " 'nose_y',\n",
       " 'nose_z',\n",
       " 'nose_v',\n",
       " 'left_shoulder_x',\n",
       " 'left_shoulder_y',\n",
       " 'left_shoulder_z',\n",
       " 'left_shoulder_v',\n",
       " 'right_shoulder_x',\n",
       " 'right_shoulder_y',\n",
       " 'right_shoulder_z',\n",
       " 'right_shoulder_v',\n",
       " 'left_hip_x',\n",
       " 'left_hip_y',\n",
       " 'left_hip_z',\n",
       " 'left_hip_v',\n",
       " 'right_hip_x',\n",
       " 'right_hip_y',\n",
       " 'right_hip_z',\n",
       " 'right_hip_v',\n",
       " 'left_knee_x',\n",
       " 'left_knee_y',\n",
       " 'left_knee_z',\n",
       " 'left_knee_v',\n",
       " 'right_knee_x',\n",
       " 'right_knee_y',\n",
       " 'right_knee_z',\n",
       " 'right_knee_v',\n",
       " 'left_ankle_x',\n",
       " 'left_ankle_y',\n",
       " 'left_ankle_z',\n",
       " 'left_ankle_v',\n",
       " 'right_ankle_x',\n",
       " 'right_ankle_y',\n",
       " 'right_ankle_z',\n",
       " 'right_ankle_v']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_csv():\n",
    "    '''\n",
    "    Create a black csv file with just columns\n",
    "    '''\n",
    "\n",
    "    # Write all the columns to a file\n",
    "    with open(\"data_frame.csv\", mode=\"w\", newline=\"\") as f:\n",
    "        csv_writer = csv.writer(f, delimiter=\",\", quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# landmarks = results.pose_landmarks.landmark\n",
    "# for res in landmarks:\n",
    "#     for lm in IMPORTANT_LMS:\n",
    "#         keypoints = landmarks[mp_pose.PoseLandmark[lm].value]\n",
    "#         print(lm, keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_landmark_to_csv(results, action: str) -> None:\n",
    "    '''\n",
    "    Export Labeled Data from detected landmark to csv\n",
    "    '''\n",
    "    landmarks = results.pose_landmarks.landmark\n",
    "    keypoints = []\n",
    "\n",
    "    try:\n",
    "        # Extract coordinate of important landmarks\n",
    "        for lm in IMPORTANT_LMS:\n",
    "            keypoint = landmarks[mp_pose.PoseLandmark[lm].value]\n",
    "            keypoints.append([keypoint.x, keypoint.y, keypoint.z, keypoint.visibility])\n",
    "        \n",
    "        keypoints = list(np.array(keypoints).flatten())\n",
    "\n",
    "        # Insert action as the label (first column)\n",
    "        keypoints.insert(0, action)\n",
    "\n",
    "        # Append new row to .csv file\n",
    "        with open(\"data_frame.csv\", mode=\"a\", newline=\"\") as f:\n",
    "            csv_writer = csv.writer(f, delimiter=\",\", quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            csv_writer.writerow(keypoints)\n",
    "        \n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract and labeled data from the video dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"../data/squat_right_2.mp4\")\n",
    "state_of_save = \"\"\n",
    "\n",
    "init_csv()\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, image = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Recolor image from BGR to RGB for mediapipe\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Recolor image from BGR to RGB for mediapipe\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Draw landmarks and connections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS, mp_drawing.DrawingSpec(color=(244, 117, 66), thickness=2, circle_radius=4), mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "        cv2.putText(image, f\"Just saved {state_of_save}\", (50, 150), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow(\"CV2\", image)\n",
    "\n",
    "        cv2.imshow(\"Media Pipe feed\", image)\n",
    "\n",
    "        # Press to extract and save to .csv\n",
    "        pressed_key = cv2.waitKey(1)\n",
    "\n",
    "        # Pressed U to label frame as UP position\n",
    "        if pressed_key == 117:\n",
    "            export_landmark_to_csv(results, \"up\")\n",
    "            state_of_save = \"up\"\n",
    "\n",
    "        # Pressed D to label frame as DOWN position\n",
    "        if pressed_key == 100:\n",
    "            export_landmark_to_csv(results, \"down\")\n",
    "            state_of_save = \"down\"\n",
    "        \n",
    "        \n",
    "        # Press Q to close cv2 window\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # (Optional)Fix bugs cannot close windows in MacOS (https://stackoverflow.com/questions/6116564/destroywindow-does-not-close-window-on-mac-using-python-and-opencv)\n",
    "    for i in range (1, 5):\n",
    "        cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9260f401923fb5c4108c543a7d176de9733d378b3752e49535ad7c43c2271b65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
